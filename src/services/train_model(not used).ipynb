{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e053ee2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All libraries imported successfully\n",
      "Working directory: c:\\Users\\Justyn Lim\\Desktop\\Python\\FYP\\SoC-SMS\\src\\services\n"
     ]
    }
   ],
   "source": [
    "# Graduation Prediction Model Training\n",
    "\n",
    "## Overview\n",
    "# This notebook trains a Logistic Regression model using XGBoost to predict whether students will graduate on-time or late based on their academic performance patterns.\n",
    "\n",
    "## Key Features\n",
    "# - Extracts course-level performance data from SQL Server database\n",
    "# - Engineers 25+ predictive features including attempt patterns, failure rates, and score statistics\n",
    "# - Trains calibrated XGBoost classifier with class imbalance handling\n",
    "# - Saves trained model with metadata and feature importance analysis\n",
    "\n",
    "## Dataset\n",
    "# - **Source**: STUDENT_SCORE and STUDENTS tables in SQL Server\n",
    "# - **Target Variable**: `on_time` (binary: 1 = on-time graduation, 0 = late graduation)\n",
    "# - **Features**: Course attempts, failure patterns, first-attempt scores, resit rates, etc.\n",
    "\n",
    "\n",
    "## 1. Setup and Imports\n",
    "\n",
    "# System path configuration\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "sys.path.insert(0, project_root)\n",
    "\n",
    "# Database connection\n",
    "from src.db.core import get_db_connection\n",
    "\n",
    "# Data processing and ML libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "import joblib\n",
    "import json\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(filename='model_training.log', level=logging.INFO)\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")\n",
    "print(f\"Working directory: {os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a675ce9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted 0 training records\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyn Lim\\AppData\\Local\\Temp\\ipykernel_35712\\3551827980.py:199: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "## 2. Data Extraction\n",
    "\n",
    "# Extract features and labels from the database using a comprehensive SQL query that:\n",
    "# - Calculates course attempt patterns for each student\n",
    "# - Computes performance metrics (scores, pass rates, failure counts)\n",
    "# - Determines on-time vs late graduation status\n",
    "# - Engineers derived features like resit rates and first-attempt pass rates\n",
    "\n",
    "\n",
    "def extract_features_and_labels():\n",
    "    \"\"\"Query database to get features and labels for graduated students\"\"\"\n",
    "    \n",
    "    conn = get_db_connection()\n",
    "\n",
    "    query = \"\"\"\n",
    "    WITH student_entry_year AS (\n",
    "        SELECT \n",
    "            MATRIC_NO,\n",
    "            CASE \n",
    "                WHEN MAX(CASE WHEN ATTEMPT_1 = 'Exempted' THEN 1 ELSE 0 END) = 1 \n",
    "                THEN 2\n",
    "                ELSE 1\n",
    "            END AS entry_year_level,\n",
    "            CASE \n",
    "                WHEN MAX(CASE WHEN ATTEMPT_1 = 'Exempted' THEN 1 ELSE 0 END) = 1 \n",
    "                THEN 2\n",
    "                ELSE 3\n",
    "            END AS expected_years\n",
    "        FROM STUDENT_SCORE\n",
    "        GROUP BY MATRIC_NO\n",
    "    ),\n",
    "\n",
    "    course_attempt_details AS (\n",
    "        SELECT \n",
    "            MATRIC_NO,\n",
    "            COURSE_CODE,\n",
    "            ATTEMPT_1,\n",
    "            ATTEMPT_2,\n",
    "            ATTEMPT_3,\n",
    "            \n",
    "            CASE \n",
    "                WHEN ATTEMPT_1 NOT IN ('-', 'Exempted') \n",
    "                THEN 1 ELSE 0 \n",
    "            END +\n",
    "            CASE \n",
    "                WHEN ATTEMPT_2 != '-' \n",
    "                THEN 1 ELSE 0 \n",
    "            END +\n",
    "            CASE \n",
    "                WHEN ATTEMPT_3 NOT IN ('-', 'NULL')\n",
    "                THEN 1 ELSE 0 \n",
    "            END AS attempts_for_course,\n",
    "            \n",
    "            CASE \n",
    "                WHEN ATTEMPT_1 NOT IN ('Exempted', '-') \n",
    "                     AND ISNUMERIC(ATTEMPT_1) = 1 \n",
    "                     AND CAST(ATTEMPT_1 AS FLOAT) < 40\n",
    "                THEN 1 ELSE 0 \n",
    "            END AS failed_first_attempt,\n",
    "            \n",
    "            CASE WHEN ATTEMPT_1 = 'Exempted' THEN 1 ELSE 0 END AS is_exempted,\n",
    "            \n",
    "            CASE \n",
    "                WHEN ATTEMPT_1 NOT IN ('Exempted', '-')\n",
    "                     AND ISNUMERIC(ATTEMPT_1) = 1 \n",
    "                THEN CAST(ATTEMPT_1 AS FLOAT)\n",
    "                ELSE NULL\n",
    "            END AS first_attempt_score,\n",
    "            \n",
    "            CASE \n",
    "                WHEN ATTEMPT_3 NOT IN ('-', 'NULL')\n",
    "                     AND ISNUMERIC(ATTEMPT_3) = 1 \n",
    "                THEN CAST(ATTEMPT_3 AS FLOAT)\n",
    "                \n",
    "                WHEN ATTEMPT_2 != '-'\n",
    "                     AND ISNUMERIC(ATTEMPT_2) = 1 \n",
    "                THEN CAST(ATTEMPT_2 AS FLOAT)\n",
    "                \n",
    "                WHEN ATTEMPT_1 NOT IN ('Exempted', '-')\n",
    "                     AND ISNUMERIC(ATTEMPT_1) = 1 \n",
    "                THEN CAST(ATTEMPT_1 AS FLOAT)\n",
    "                \n",
    "                ELSE NULL\n",
    "            END AS final_score,\n",
    "            \n",
    "            CASE \n",
    "                WHEN (\n",
    "                    (ATTEMPT_3 NOT IN ('-', 'NULL') AND ISNUMERIC(ATTEMPT_3) = 1 AND CAST(ATTEMPT_3 AS FLOAT) >= 40)\n",
    "                    OR (ATTEMPT_2 != '-' AND ISNUMERIC(ATTEMPT_2) = 1 AND CAST(ATTEMPT_2 AS FLOAT) >= 40)\n",
    "                    OR (ATTEMPT_1 NOT IN ('Exempted', '-') AND ISNUMERIC(ATTEMPT_1) = 1 AND CAST(ATTEMPT_1 AS FLOAT) >= 40)\n",
    "                )\n",
    "                THEN 1 ELSE 0 \n",
    "            END AS eventually_passed\n",
    "            \n",
    "        FROM STUDENT_SCORE\n",
    "    ),\n",
    "\n",
    "    student_features_enhanced AS (\n",
    "        SELECT \n",
    "            MATRIC_NO,\n",
    "            \n",
    "            COUNT(DISTINCT COURSE_CODE) as total_courses,\n",
    "            SUM(is_exempted) as exempted_courses,\n",
    "            COUNT(DISTINCT COURSE_CODE) - SUM(is_exempted) as actual_courses_taken,\n",
    "            \n",
    "            SUM(CASE WHEN attempts_for_course = 1 THEN 1 ELSE 0 END) as courses_passed_first_attempt,\n",
    "            SUM(CASE WHEN attempts_for_course = 2 THEN 1 ELSE 0 END) as courses_with_2_attempts,\n",
    "            SUM(CASE WHEN attempts_for_course = 3 THEN 1 ELSE 0 END) as courses_with_3_attempts,\n",
    "            SUM(CASE WHEN attempts_for_course >= 2 THEN 1 ELSE 0 END) as total_courses_needing_resits,\n",
    "            \n",
    "            SUM(failed_first_attempt) as total_first_attempt_failures,\n",
    "            SUM(CASE WHEN failed_first_attempt = 1 AND eventually_passed = 0 THEN 1 ELSE 0 END) as courses_never_passed,\n",
    "            SUM(CASE WHEN failed_first_attempt = 1 AND eventually_passed = 1 THEN 1 ELSE 0 END) as courses_passed_after_failing,\n",
    "            \n",
    "            AVG(first_attempt_score) as avg_first_attempt_score,\n",
    "            MIN(first_attempt_score) as lowest_first_attempt_score,\n",
    "            STDEV(first_attempt_score) as first_attempt_score_std_dev,\n",
    "            \n",
    "            AVG(final_score) as avg_final_score,\n",
    "            MIN(final_score) as lowest_final_score,\n",
    "            MAX(final_score) as highest_final_score,\n",
    "            \n",
    "            SUM(CASE WHEN first_attempt_score >= 70 THEN 1 ELSE 0 END) as courses_with_distinction_first_attempt,\n",
    "            SUM(CASE WHEN first_attempt_score >= 40 AND first_attempt_score < 50 THEN 1 ELSE 0 END) as courses_barely_passed_first_attempt,\n",
    "            SUM(CASE WHEN final_score = 40 AND attempts_for_course > 1 THEN 1 ELSE 0 END) as courses_capped_at_40,\n",
    "            SUM(CASE WHEN final_score < 40 THEN 1 ELSE 0 END) as courses_still_failing\n",
    "            \n",
    "        FROM course_attempt_details\n",
    "        GROUP BY MATRIC_NO\n",
    "    ),\n",
    "\n",
    "    graduation_labels AS (\n",
    "        SELECT \n",
    "            s.MATRIC_NO,\n",
    "            s.COHORT,\n",
    "            s.GRADUATED_ON,\n",
    "            sey.entry_year_level,\n",
    "            sey.expected_years,\n",
    "            \n",
    "            DATEPART(YEAR, s.COHORT) AS entry_year,\n",
    "            DATEPART(MONTH, s.COHORT) AS entry_month,\n",
    "            \n",
    "            2000 + CAST(SUBSTRING(s.GRADUATED_ON, 2, 2) AS INT) AS grad_year,\n",
    "            CAST(SUBSTRING(s.GRADUATED_ON, 5, 1) AS INT) AS grad_month,\n",
    "            \n",
    "            DATEPART(YEAR, DATEADD(YEAR, sey.expected_years, s.COHORT)) AS expected_grad_year,\n",
    "            DATEPART(MONTH, s.COHORT) AS expected_grad_month,\n",
    "            \n",
    "            CASE \n",
    "                WHEN 2000 + CAST(SUBSTRING(s.GRADUATED_ON, 2, 2) AS INT) < DATEPART(YEAR, DATEADD(YEAR, sey.expected_years, s.COHORT)) THEN 1\n",
    "                WHEN 2000 + CAST(SUBSTRING(s.GRADUATED_ON, 2, 2) AS INT) = DATEPART(YEAR, DATEADD(YEAR, sey.expected_years, s.COHORT)) \n",
    "                     AND CAST(SUBSTRING(s.GRADUATED_ON, 5, 1) AS INT) <= DATEPART(MONTH, s.COHORT) THEN 1\n",
    "                ELSE 0\n",
    "            END AS on_time\n",
    "            \n",
    "        FROM STUDENTS s\n",
    "        INNER JOIN student_entry_year sey ON s.MATRIC_NO = sey.MATRIC_NO\n",
    "        WHERE \n",
    "            s.STUDENT_STATUS = 'Graduate'\n",
    "            AND s.GRADUATED_ON != '-'\n",
    "            AND s.GRADUATED_ON IS NOT NULL\n",
    "    )\n",
    "\n",
    "    SELECT \n",
    "        gl.*,\n",
    "        \n",
    "        sfe.total_courses,\n",
    "        sfe.exempted_courses,\n",
    "        sfe.actual_courses_taken,\n",
    "        sfe.courses_passed_first_attempt,\n",
    "        sfe.courses_with_2_attempts,\n",
    "        sfe.courses_with_3_attempts,\n",
    "        sfe.total_courses_needing_resits,\n",
    "        sfe.total_first_attempt_failures,\n",
    "        sfe.courses_never_passed,\n",
    "        sfe.courses_passed_after_failing,\n",
    "        sfe.avg_first_attempt_score,\n",
    "        sfe.lowest_first_attempt_score,\n",
    "        sfe.first_attempt_score_std_dev,\n",
    "        sfe.avg_final_score,\n",
    "        sfe.lowest_final_score,\n",
    "        sfe.highest_final_score,\n",
    "        sfe.courses_with_distinction_first_attempt,\n",
    "        sfe.courses_barely_passed_first_attempt,\n",
    "        sfe.courses_capped_at_40,\n",
    "        sfe.courses_still_failing,\n",
    "        \n",
    "        CAST(sfe.courses_passed_first_attempt AS FLOAT) / NULLIF(sfe.actual_courses_taken, 0) as first_attempt_pass_rate,\n",
    "        CAST(sfe.total_courses_needing_resits AS FLOAT) / NULLIF(sfe.actual_courses_taken, 0) as resit_rate,\n",
    "        CAST(sfe.total_first_attempt_failures AS FLOAT) / NULLIF(sfe.actual_courses_taken, 0) as first_attempt_failure_rate,\n",
    "        CAST(sfe.courses_with_3_attempts AS FLOAT) / NULLIF(sfe.total_courses_needing_resits, 0) as third_attempt_rate,\n",
    "        CAST(sfe.courses_capped_at_40 AS FLOAT) / NULLIF(sfe.total_courses_needing_resits, 0) as resit_success_rate\n",
    "        \n",
    "    FROM graduation_labels gl\n",
    "    INNER JOIN student_features_enhanced sfe ON gl.MATRIC_NO = sfe.MATRIC_NO\n",
    "    ORDER BY gl.MATRIC_NO\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "    \n",
    "    logging.info(f\"Extracted {len(df)} training records from database\")\n",
    "    print(f\"✓ Extracted {len(df)} training records\")\n",
    "    return df\n",
    "\n",
    "# Execute data extraction\n",
    "df = extract_features_and_labels()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3edf80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (0, 37)\n",
      "\n",
      "Column names:\n",
      "['MATRIC_NO', 'COHORT', 'GRADUATED_ON', 'entry_year_level', 'expected_years', 'entry_year', 'entry_month', 'grad_year', 'grad_month', 'expected_grad_year', 'expected_grad_month', 'on_time', 'total_courses', 'exempted_courses', 'actual_courses_taken', 'courses_passed_first_attempt', 'courses_with_2_attempts', 'courses_with_3_attempts', 'total_courses_needing_resits', 'total_first_attempt_failures', 'courses_never_passed', 'courses_passed_after_failing', 'avg_first_attempt_score', 'lowest_first_attempt_score', 'first_attempt_score_std_dev', 'avg_final_score', 'lowest_final_score', 'highest_final_score', 'courses_with_distinction_first_attempt', 'courses_barely_passed_first_attempt', 'courses_capped_at_40', 'courses_still_failing', 'first_attempt_pass_rate', 'resit_rate', 'first_attempt_failure_rate', 'third_attempt_rate', 'resit_success_rate']\n",
      "\n",
      "On-time graduation distribution:\n",
      "Series([], Name: count, dtype: int64)\n",
      "\n",
      "Class percentages:\n",
      "Series([], Name: proportion, dtype: float64)\n",
      "\n",
      "Sample records:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MATRIC_NO</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>GRADUATED_ON</th>\n",
       "      <th>entry_year_level</th>\n",
       "      <th>expected_years</th>\n",
       "      <th>entry_year</th>\n",
       "      <th>entry_month</th>\n",
       "      <th>grad_year</th>\n",
       "      <th>grad_month</th>\n",
       "      <th>expected_grad_year</th>\n",
       "      <th>...</th>\n",
       "      <th>highest_final_score</th>\n",
       "      <th>courses_with_distinction_first_attempt</th>\n",
       "      <th>courses_barely_passed_first_attempt</th>\n",
       "      <th>courses_capped_at_40</th>\n",
       "      <th>courses_still_failing</th>\n",
       "      <th>first_attempt_pass_rate</th>\n",
       "      <th>resit_rate</th>\n",
       "      <th>first_attempt_failure_rate</th>\n",
       "      <th>third_attempt_rate</th>\n",
       "      <th>resit_success_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [MATRIC_NO, COHORT, GRADUATED_ON, entry_year_level, expected_years, entry_year, entry_month, grad_year, grad_month, expected_grad_year, expected_grad_month, on_time, total_courses, exempted_courses, actual_courses_taken, courses_passed_first_attempt, courses_with_2_attempts, courses_with_3_attempts, total_courses_needing_resits, total_first_attempt_failures, courses_never_passed, courses_passed_after_failing, avg_first_attempt_score, lowest_first_attempt_score, first_attempt_score_std_dev, avg_final_score, lowest_final_score, highest_final_score, courses_with_distinction_first_attempt, courses_barely_passed_first_attempt, courses_capped_at_40, courses_still_failing, first_attempt_pass_rate, resit_rate, first_attempt_failure_rate, third_attempt_rate, resit_success_rate]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 3. Exploratory Data Analysis\n",
    "\n",
    "# Examine the extracted dataset to understand class distribution and data quality.\n",
    "\n",
    "print(f\"Training data shape: {df.shape}\")\n",
    "print(f\"\\nColumn names:\\n{df.columns.tolist()}\")\n",
    "print(f\"\\nOn-time graduation distribution:\\n{df['on_time'].value_counts()}\")\n",
    "print(f\"\\nClass percentages:\")\n",
    "print(df['on_time'].value_counts(normalize=True) * 100)\n",
    "\n",
    "# Display sample records\n",
    "print(f\"\\nSample records:\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "690019d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MATRIC_NO</th>\n",
       "      <th>COHORT</th>\n",
       "      <th>GRADUATED_ON</th>\n",
       "      <th>entry_year_level</th>\n",
       "      <th>expected_years</th>\n",
       "      <th>entry_year</th>\n",
       "      <th>entry_month</th>\n",
       "      <th>grad_year</th>\n",
       "      <th>grad_month</th>\n",
       "      <th>expected_grad_year</th>\n",
       "      <th>...</th>\n",
       "      <th>highest_final_score</th>\n",
       "      <th>courses_with_distinction_first_attempt</th>\n",
       "      <th>courses_barely_passed_first_attempt</th>\n",
       "      <th>courses_capped_at_40</th>\n",
       "      <th>courses_still_failing</th>\n",
       "      <th>first_attempt_pass_rate</th>\n",
       "      <th>resit_rate</th>\n",
       "      <th>first_attempt_failure_rate</th>\n",
       "      <th>third_attempt_rate</th>\n",
       "      <th>resit_success_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MATRIC_NO COHORT GRADUATED_ON entry_year_level expected_years  \\\n",
       "count          0      0            0                0              0   \n",
       "unique         0      0            0                0              0   \n",
       "top          NaN    NaN          NaN              NaN            NaN   \n",
       "freq         NaN    NaN          NaN              NaN            NaN   \n",
       "\n",
       "       entry_year entry_month grad_year grad_month expected_grad_year  ...  \\\n",
       "count           0           0         0          0                  0  ...   \n",
       "unique          0           0         0          0                  0  ...   \n",
       "top           NaN         NaN       NaN        NaN                NaN  ...   \n",
       "freq          NaN         NaN       NaN        NaN                NaN  ...   \n",
       "\n",
       "       highest_final_score courses_with_distinction_first_attempt  \\\n",
       "count                    0                                      0   \n",
       "unique                   0                                      0   \n",
       "top                    NaN                                    NaN   \n",
       "freq                   NaN                                    NaN   \n",
       "\n",
       "       courses_barely_passed_first_attempt courses_capped_at_40  \\\n",
       "count                                    0                    0   \n",
       "unique                                   0                    0   \n",
       "top                                    NaN                  NaN   \n",
       "freq                                   NaN                  NaN   \n",
       "\n",
       "       courses_still_failing first_attempt_pass_rate resit_rate  \\\n",
       "count                      0                       0          0   \n",
       "unique                     0                       0          0   \n",
       "top                      NaN                     NaN        NaN   \n",
       "freq                     NaN                     NaN        NaN   \n",
       "\n",
       "       first_attempt_failure_rate third_attempt_rate resit_success_rate  \n",
       "count                           0                  0                  0  \n",
       "unique                          0                  0                  0  \n",
       "top                           NaN                NaN                NaN  \n",
       "freq                          NaN                NaN                NaN  \n",
       "\n",
       "[4 rows x 37 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in key features\n",
    "print(\"Missing values per column:\")\n",
    "df.isnull().sum()[df.isnull().sum() > 0]\n",
    "\n",
    "# Basic statistics\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b15e8cb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ERROR: No training data found!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## 4. Data Validation\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Check if we have sufficient data for training, especially for the minority class (late graduates).\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(df) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mERROR: No training data found!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m on_time_count \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mon_time\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m      9\u001b[0m late_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df) \u001b[38;5;241m-\u001b[39m on_time_count\n",
      "\u001b[1;31mValueError\u001b[0m: ERROR: No training data found!"
     ]
    }
   ],
   "source": [
    "## 4. Data Validation\n",
    "\n",
    "# Check if we have sufficient data for training, especially for the minority class (late graduates).\n",
    "\n",
    "if len(df) == 0:\n",
    "    raise ValueError(\"ERROR: No training data found!\")\n",
    "\n",
    "on_time_count = df['on_time'].sum()\n",
    "late_count = len(df) - on_time_count\n",
    "\n",
    "print(f\"Class distribution:\")\n",
    "print(f\"  - On-time graduates: {on_time_count} ({on_time_count/len(df)*100:.1f}%)\")\n",
    "print(f\"  - Late graduates: {late_count} ({late_count/len(df)*100:.1f}%)\")\n",
    "\n",
    "if late_count == 0:\n",
    "    raise ValueError(\"⚠ WARNING: No late graduates found! Cannot train binary classifier.\")\n",
    "\n",
    "if late_count < 5 or on_time_count < 5:\n",
    "    print(f\"\\n⚠ WARNING: Very limited data for one class!\")\n",
    "    print(f\"Training will proceed without probability calibration due to small sample size.\")\n",
    "    use_calibration = False\n",
    "else:\n",
    "    use_calibration = True\n",
    "    \n",
    "print(f\"\\nCalibration: {'Enabled' if use_calibration else 'Disabled'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c60192",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Feature Engineering\n",
    "\n",
    "# Define the feature set for model training. These features capture academic performance patterns that predict graduation timing.\n",
    "\n",
    "### Feature Categories:\n",
    "# 1. **Basic**: Entry year level, course counts\n",
    "# 2. **Attempt Patterns**: Number of courses requiring 1, 2, or 3 attempts\n",
    "# 3. **Failure Patterns**: First-attempt failures, never-passed courses\n",
    "# 4. **Score Metrics**: Average, minimum, standard deviation of scores\n",
    "# 5. **Derived Ratios**: Pass rates, resit rates, failure rates (key predictors)\n",
    "\n",
    "\n",
    "# Define feature columns\n",
    "feature_cols = [\n",
    "    # Basic\n",
    "    'entry_year_level',\n",
    "    'total_courses',\n",
    "    'actual_courses_taken',\n",
    "    \n",
    "    # Attempt patterns (KEY PREDICTORS)\n",
    "    'courses_passed_first_attempt',\n",
    "    'courses_with_2_attempts',\n",
    "    'courses_with_3_attempts',\n",
    "    'total_courses_needing_resits',\n",
    "    \n",
    "    # Failure patterns (STRONG PREDICTORS)\n",
    "    'total_first_attempt_failures',\n",
    "    'courses_never_passed',\n",
    "    'courses_passed_after_failing',\n",
    "    \n",
    "    # First attempt performance (VERY STRONG PREDICTORS)\n",
    "    'avg_first_attempt_score',\n",
    "    'lowest_first_attempt_score',\n",
    "    'first_attempt_score_std_dev',\n",
    "    \n",
    "    # Final performance\n",
    "    'avg_final_score',\n",
    "    'lowest_final_score',\n",
    "    \n",
    "    # Success indicators\n",
    "    'courses_with_distinction_first_attempt',\n",
    "    'courses_barely_passed_first_attempt',\n",
    "    'courses_capped_at_40',\n",
    "    \n",
    "    # Derived ratios (CRITICAL PREDICTORS)\n",
    "    'first_attempt_pass_rate',\n",
    "    'resit_rate',\n",
    "    'first_attempt_failure_rate',\n",
    "    'third_attempt_rate',\n",
    "    'resit_success_rate'\n",
    "]\n",
    "\n",
    "print(f\"Total features: {len(feature_cols)}\")\n",
    "print(\"\\nFeature list:\")\n",
    "for i, feat in enumerate(feature_cols, 1):\n",
    "    print(f\"{i:2d}. {feat}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95acb289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare feature matrix and target variable\n",
    "X = df[feature_cols].fillna(0)\n",
    "y = df['on_time']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target variable shape: {y.shape}\")\n",
    "print(f\"\\nFeature data types:\\n{X.dtypes.value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1538f636",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. Train-Test Split\n",
    "\n",
    "# Split data into training and test sets. For very small datasets (< 20 samples), use all data for training.\n",
    "\n",
    "# Determine if we should create a test set\n",
    "if len(df) < 20 or late_count < 5:\n",
    "    print(f\"⚠ Using all {len(df)} samples for training (no test set due to small sample size)\")\n",
    "    X_train, X_test = X, None\n",
    "    y_train, y_test = y, None\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "    print(f\"Training set: {len(X_train)} samples\")\n",
    "    print(f\"Test set: {len(X_test)} samples\")\n",
    "\n",
    "print(f\"\\nTraining set class distribution:\")\n",
    "print(y_train.value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd0c646",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 7. Model Configuration\n",
    "\n",
    "# Configure XGBoost classifier with class imbalance handling using `scale_pos_weight`.\n",
    "\n",
    "# Calculate class weights\n",
    "pos = y_train.sum()\n",
    "neg = (y_train == 0).sum()\n",
    "scale_pos_weight = max(1.0, neg / max(1, pos))\n",
    "\n",
    "print(f\"Class balance in training set:\")\n",
    "print(f\"  - On-time (positive): {pos}\")\n",
    "print(f\"  - Late (negative): {neg}\")\n",
    "print(f\"  - Scale weight: {scale_pos_weight:.2f}\")\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    tree_method='hist',\n",
    "    random_state=42,\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\n✓ XGBoost classifier configured\")\n",
    "print(f\"Parameters: {xgb.get_params()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af292ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8. Model Training\n",
    "\n",
    "# Train the XGBoost model and optionally calibrate probabilities using CalibratedClassifierCV.\n",
    "\n",
    "\n",
    "# Train base XGBoost model\n",
    "print(\"Training XGBoost model...\")\n",
    "xgb.fit(X_train, y_train)\n",
    "print(\"✓ Base model training complete\")\n",
    "\n",
    "# Calibrate probabilities if sufficient data\n",
    "if use_calibration and neg >= 3 and pos >= 3:\n",
    "    print(\"\\nCalibrating probabilities...\")\n",
    "    try:\n",
    "        cv_folds = 2 if min(neg, pos) < 5 else 3\n",
    "        xgb_cal = CalibratedClassifierCV(xgb, method='sigmoid', cv=cv_folds)\n",
    "        xgb_cal.fit(X_train, y_train)\n",
    "        final_model = xgb_cal\n",
    "        print(f\"✓ Calibration successful (cv={cv_folds})\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠ Calibration failed: {e}\")\n",
    "        print(\"Using uncalibrated model instead.\")\n",
    "        final_model = xgb\n",
    "else:\n",
    "    print(\"\\n⚠ Skipping calibration due to insufficient data\")\n",
    "    final_model = xgb\n",
    "\n",
    "print(\"\\n✓ Final model ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b475866",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 9. Model Evaluation\n",
    "\n",
    "# Evaluate model performance using AUC-ROC and classification report.\n",
    "\n",
    "\n",
    "# Evaluate on test set if available, otherwise on training set\n",
    "if X_test is not None and y_test is not None:\n",
    "    print(\"=\"*60)\n",
    "    print(\"Model Performance (Test Set)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    y_pred_proba = final_model.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "    \n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    print(f\"\\nAUC-ROC: {auc:.4f}\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred, target_names=['Late', 'On-time'], zero_division=0))\n",
    "else:\n",
    "    print(\"=\"*60)\n",
    "    print(\"Model Performance (Training Set - no test set available)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    y_pred_proba = final_model.predict_proba(X_train)[:, 1]\n",
    "    y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "    \n",
    "    auc = roc_auc_score(y_train, y_pred_proba)\n",
    "    \n",
    "    print(f\"\\nAUC-ROC: {auc:.4f} (Warning: May be optimistic)\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(classification_report(y_train, y_pred, target_names=['Late', 'On-time'], zero_division=0))\n",
    "\n",
    "# Store AUC for later use\n",
    "model_auc = auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaabe11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 10. Feature Importance Analysis\n",
    "\n",
    "# Analyze which features contribute most to predictions.\n",
    "\n",
    "\n",
    "# Extract feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': xgb.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 10 Most Important Features:\")\n",
    "print(feature_importance.head(10).to_string(index=False))\n",
    "\n",
    "print(f\"\\nTop 5 features contribute {feature_importance.head(5)['importance'].sum():.2%} of total importance\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5103d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance (top 15)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = feature_importance.head(15)\n",
    "plt.barh(range(len(top_features)), top_features['importance'])\n",
    "plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 15 Most Important Features')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936f746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 11. Save Model and Metadata\n",
    "\n",
    "# Save the trained model, feature columns, metadata, and feature importance for deployment.\n",
    "\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Generate timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "model_path = f'models/graduation_model_{timestamp}.joblib'\n",
    "\n",
    "# Save models\n",
    "joblib.dump(final_model, model_path)\n",
    "joblib.dump(final_model, 'models/graduation_model_latest.joblib')\n",
    "joblib.dump(feature_cols, 'models/feature_columns.joblib')\n",
    "\n",
    "print(f\"✓ Model saved to {model_path}\")\n",
    "print(f\"✓ Latest model: models/graduation_model_latest.joblib\")\n",
    "print(f\"✓ Feature columns: models/feature_columns.joblib\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8076b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata\n",
    "metadata = {\n",
    "    'timestamp': timestamp,\n",
    "    'total_samples': len(df),\n",
    "    'on_time_count': int(on_time_count),\n",
    "    'late_count': int(late_count),\n",
    "    'auc': float(model_auc),\n",
    "    'calibrated': use_calibration and neg >= 3 and pos >= 3,\n",
    "    'features': feature_cols,\n",
    "    'feature_count': len(feature_cols)\n",
    "}\n",
    "\n",
    "with open('models/model_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"✓ Metadata saved to models/model_metadata.json\")\n",
    "\n",
    "# Display metadata\n",
    "print(\"\\nModel Metadata:\")\n",
    "for key, value in metadata.items():\n",
    "    if key != 'features':  # Skip features list for readability\n",
    "        print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffadb523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature importance\n",
    "feature_importance_path = f'models/feature_importance_{timestamp}.csv'\n",
    "feature_importance.to_csv(feature_importance_path, index=False)\n",
    "\n",
    "print(f\"✓ Feature importance saved to {feature_importance_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cdfb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 12. Training Summary\n",
    "\n",
    "# Final summary of model training results and next steps.\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n✓ Model AUC: {model_auc:.4f}\")\n",
    "print(f\"✓ Total samples: {len(df)}\")\n",
    "print(f\"✓ Features used: {len(feature_cols)}\")\n",
    "print(f\"✓ Calibration: {'Yes' if metadata['calibrated'] else 'No'}\")\n",
    "print(f\"\\n✓ Model saved to: {model_path}\")\n",
    "print(f\"\\nNOTE: Model trained with enhanced course-level features.\")\n",
    "print(\"Performance will improve as more graduates are added to the system.\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  1. Review feature importance above\")\n",
    "print(\"  2. Test model predictions on new students\")\n",
    "print(\"  3. Integrate model into Flask API\")\n",
    "print(\"  4. Monitor performance and retrain periodically\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
